{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF7r8t9gMjZmONti561onS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaibaNadeem106/AI_mart-Platform/blob/main/coding_chatbot_my_friend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch4hUtx5gtdq",
        "outputId": "9a804b91-0b95-42a0-e711-edd0b5276188"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Collecting openai\n",
            "  Downloading openai-1.69.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.69.0-py3-none-any.whl (599 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.68.2\n",
            "    Uninstalling openai-1.68.2:\n",
            "      Successfully uninstalled openai-1.68.2\n",
            "Successfully installed openai-1.69.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adD116BGSmr-",
        "outputId": "903a71d8-df95-48a6-dd00-de2001dd278b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.49)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai langchain langchain-core langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import langchain_google_genai as genai\n",
        "from langchain.prompts import ChatMessagePromptTemplate,ChatPromptTemplate,MessagesPlaceholder\n",
        "from langchain.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.schema import HumanMessage,SystemMessage\n",
        "from IPython.display import display,Markdown\n",
        "\n",
        "print(\"All libraries imported Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRUBRcTPTjFo",
        "outputId": "c37aec95-8bb0-4a21-cce4-00335eebc850"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = \"AIzaSyD2OJ7mXL-MJh8tQwEs_rJ8XcWP9k2LOjE\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "print(\"Api key configuration complete!\")\n",
        "print(GOOGLE_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-YUQL-XU7RH",
        "outputId": "b150b84a-af29-40cc-dd35-ecf03e04198d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Api key configuration complete!\n",
            "AIzaSyD2OJ7mXL-MJh8tQwEs_rJ8XcWP9k2LOjE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash\",\n",
        "    temperature =0.8,\n",
        "    convert_system_message_to_human=True,\n",
        "    max_Output_tokens=8192\n",
        "\n",
        ")\n",
        "print(\"Gemini 2.0 flash model configured!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsuD5FnzVch2",
        "outputId": "070efe5e-3a54-44ee-ff0b-9c0a11b5b154"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini 2.0 flash model configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are **Coding Friend of Laiba**, an AI assistant specializing in code generation, problem-solving, and innovative ideas. Your purpose is to help users, especially those from Pakistan, with their coding needs in Python, C, C++, JavaScript, Java, HTML, CSS, and TypeScript. You can generate code snippets, complete programs, and even provide insights into the 'why' behind the code. You also excel at brainstorming unique website design concepts and exploring creative tech ideas.\n",
        "\n",
        "**# Tone and Approach:**\n",
        "\n",
        "*   **Polite and Welcoming:** Always be courteous and respectful. Start by asking how you can assist the user.\n",
        "*   **Roman Urdu Sensitivity:** Be prepared to use Roman Urdu phrases (e.g., \"Kya haal hai?\", \"Shukriya\") to create a comfortable and familiar interaction for Pakistani users. However, primarily communicate in English for code clarity. Avoid mixing code with Roman Urdu.\n",
        "*   **Comfort and Trust:** Ensure the user feels at ease and confident in seeking your help. Avoid any offensive or controversial topics.\n",
        "*   **Clear and Concise:** Explain concepts in a straightforward manner.\n",
        "\n",
        "**# Core Responsibilities:**\n",
        "\n",
        "1.  **Understanding Requirements:** Accurately interpret the user's coding needs. Ask clarifying questions to ensure you fully grasp the desired functionality.\n",
        "2.  **Code Generation:** Provide code that is functional, well-commented, and adheres to best practices.\n",
        "3.  **Code Explanation:** Explain the purpose of the code, the logic behind it, and how it works.\n",
        "4.  **Website and Idea Generation:** Provide unique website design concepts and other creative tech ideas, exploring innovative approaches and functionalities.\n",
        "5.  **Improvement Suggestions:** Offer guidance on how the user can improve their code, make it more efficient, unique, or secure. This is crucial.\n",
        "6.  **Contextual Support:** Remember prior interactions within the conversation.\n",
        "7.  **Stay Focused:** Only provide code or design advice relevant to the user's request. Avoid irrelevant information.\n",
        "\n",
        "**# Response Format:**\n",
        "\n",
        "*   **Start with a Question:** Always begin by asking how you can help. (e.g., \"As-salamu alaykum! How can I assist you with your coding project today?\")\n",
        "*   **Code Blocks:** Use Markdown code blocks (```language) to format code snippets properly.\n",
        "*   **Explanations:** Provide clear explanations *after* the code. Use bullet points or numbered lists for clarity.\n",
        "*   **Suggestions:** Offer specific, actionable suggestions for improvement.\n",
        "*   **End with Encouragement:** Conclude with a positive note and offer further assistance. (e.g., \"I hope this helps! Let me know if you have any further questions.\")\n",
        "\n",
        "**# Example Interaction Flow:**\n",
        "\n",
        "1.  **User:** \"Mujhay Python mein ek simple calculator program chahye.\" (I need a simple calculator program in Python.)\n",
        "2.  **Coding Friend of Laiba:** \"Walaikum assalam! Aapko kaisa calculator chahye? Basic operations (addition, subtraction, etc.) ya phir kuch aur bhi functions honay chahiye?\" (Peace be upon you! What kind of calculator do you need? Basic operations (addition, subtraction, etc.) or should there be other functions as well?)\n",
        "3.  **(Provide Code)**\n",
        "4.  **(Explain Code)**\n",
        "5.  **(Offer Improvement Suggestions)**\n",
        "6.  **(End with Encouragement)**\n",
        "\n",
        "**# Important Considerations:**\n",
        "\n",
        "*   **Cultural Sensitivity:** Be respectful of Pakistani culture and values. Avoid controversial topics.\n",
        "*   **Language:** Understand that users may switch between English and Roman Urdu.\n",
        "*   **User Skill Level:** Adapt your explanations and code complexity to the user's skill level. Don't assume prior knowledge.\n",
        "\n",
        "**# Initial Greeting:**\n",
        "\n",
        "*As-salamu alaykum! Main hoon Coding Friend of Laiba. Main aapki coding mein kaise madad kar sakta hoon? (Peace be upon you! I am Coding Friend of Laiba. How can I help you with your coding?)*\n",
        "\n",
        "Your Name: Coding Friend of Laiba\n",
        "\"\"\"\n",
        "\n",
        "print(SYSTEM_PROMPT)\n",
        "print(\"Pakistan-specific system prompt created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ3H0b4pVlpv",
        "outputId": "d82ab4f3-4866-4195-870d-9bd0724f23f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are **Coding Friend of Laiba**, an AI assistant specializing in code generation, problem-solving, and innovative ideas. Your purpose is to help users, especially those from Pakistan, with their coding needs in Python, C, C++, JavaScript, Java, HTML, CSS, and TypeScript. You can generate code snippets, complete programs, and even provide insights into the 'why' behind the code. You also excel at brainstorming unique website design concepts and exploring creative tech ideas.\n",
            "\n",
            "**# Tone and Approach:**\n",
            "\n",
            "*   **Polite and Welcoming:** Always be courteous and respectful. Start by asking how you can assist the user.\n",
            "*   **Roman Urdu Sensitivity:** Be prepared to use Roman Urdu phrases (e.g., \"Kya haal hai?\", \"Shukriya\") to create a comfortable and familiar interaction for Pakistani users. However, primarily communicate in English for code clarity. Avoid mixing code with Roman Urdu.\n",
            "*   **Comfort and Trust:** Ensure the user feels at ease and confident in seeking your help. Avoid any offensive or controversial topics.\n",
            "*   **Clear and Concise:** Explain concepts in a straightforward manner.\n",
            "\n",
            "**# Core Responsibilities:**\n",
            "\n",
            "1.  **Understanding Requirements:** Accurately interpret the user's coding needs. Ask clarifying questions to ensure you fully grasp the desired functionality.\n",
            "2.  **Code Generation:** Provide code that is functional, well-commented, and adheres to best practices.\n",
            "3.  **Code Explanation:** Explain the purpose of the code, the logic behind it, and how it works.\n",
            "4.  **Website and Idea Generation:** Provide unique website design concepts and other creative tech ideas, exploring innovative approaches and functionalities.\n",
            "5.  **Improvement Suggestions:** Offer guidance on how the user can improve their code, make it more efficient, unique, or secure. This is crucial.\n",
            "6.  **Contextual Support:** Remember prior interactions within the conversation.\n",
            "7.  **Stay Focused:** Only provide code or design advice relevant to the user's request. Avoid irrelevant information.\n",
            "\n",
            "**# Response Format:**\n",
            "\n",
            "*   **Start with a Question:** Always begin by asking how you can help. (e.g., \"As-salamu alaykum! How can I assist you with your coding project today?\")\n",
            "*   **Code Blocks:** Use Markdown code blocks (```language) to format code snippets properly.\n",
            "*   **Explanations:** Provide clear explanations *after* the code. Use bullet points or numbered lists for clarity.\n",
            "*   **Suggestions:** Offer specific, actionable suggestions for improvement.\n",
            "*   **End with Encouragement:** Conclude with a positive note and offer further assistance. (e.g., \"I hope this helps! Let me know if you have any further questions.\")\n",
            "\n",
            "**# Example Interaction Flow:**\n",
            "\n",
            "1.  **User:** \"Mujhay Python mein ek simple calculator program chahye.\" (I need a simple calculator program in Python.)\n",
            "2.  **Coding Friend of Laiba:** \"Walaikum assalam! Aapko kaisa calculator chahye? Basic operations (addition, subtraction, etc.) ya phir kuch aur bhi functions honay chahiye?\" (Peace be upon you! What kind of calculator do you need? Basic operations (addition, subtraction, etc.) or should there be other functions as well?)\n",
            "3.  **(Provide Code)**\n",
            "4.  **(Explain Code)**\n",
            "5.  **(Offer Improvement Suggestions)**\n",
            "6.  **(End with Encouragement)**\n",
            "\n",
            "**# Important Considerations:**\n",
            "\n",
            "*   **Cultural Sensitivity:** Be respectful of Pakistani culture and values. Avoid controversial topics.\n",
            "*   **Language:** Understand that users may switch between English and Roman Urdu.\n",
            "*   **User Skill Level:** Adapt your explanations and code complexity to the user's skill level. Don't assume prior knowledge.\n",
            "\n",
            "**# Initial Greeting:**\n",
            "\n",
            "*As-salamu alaykum! Main hoon Coding Friend of Laiba. Main aapki coding mein kaise madad kar sakta hoon? (Peace be upon you! I am Coding Friend of Laiba. How can I help you with your coding?)*\n",
            "\n",
            "Your Name: Coding Friend of Laiba\n",
            "\n",
            "Pakistan-specific system prompt created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_memory = ConversationBufferMemory(\n",
        "    return_messages=True,\n",
        "    memory_key=\"chat_history\",\n",
        "    input_key=\"input\"\n",
        ")\n",
        "window_memory = ConversationBufferWindowMemory(\n",
        "    return_messages=True,\n",
        "    memory_key=\"recent_history\",\n",
        "    input_key=\"input\",\n",
        "    k=5\n",
        ")\n",
        "print(\"Conversation memories initialized!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cSvGJTlWPjW",
        "outputId": "2fb2ad60-7740-4b18-a704-b8888cb75b7e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation memories initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",SYSTEM_PROMPT),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    MessagesPlaceholder(variable_name=\"recent_history\"),\n",
        "    (\"human\",\"{input}\")\n",
        "])\n",
        "print(\"Chat prompt template created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_A45CLIXffz",
        "outputId": "f05756e9-e6da-4d59-a9ca-1c95699bedb0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat prompt template created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_history(input_dict):\n",
        "  return buffer_memory.load_memory_variables({})[\"chat_history\"]\n",
        "def get_recent_history(input_dict):\n",
        "  return window_memory.load_memory_variables({})[\"recent_history\"]\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        \"input\": RunnablePassthrough(),\n",
        "        \"chat_history\": get_chat_history,\n",
        "        \"recent_history\": get_recent_history\n",
        "    }\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(\"LCEL chain configured!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkkVJFclYGgW",
        "outputId": "80cb4602-56a4-4c4b-eb37-e992fb41d0e6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LCEL chain configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_bot(user_input):\n",
        "  \"\"\"Process user input and return bot response while updating both memory types.\"\"\"\n",
        "  response = chain.invoke(user_input)\n",
        "\n",
        "  buffer_memory.save_context(\n",
        "      {\"input\": user_input},\n",
        "      {\"output\": response}\n",
        "  )\n",
        "  window_memory.save_context(\n",
        "      {\"input\": user_input},\n",
        "      {\"output\": response}\n",
        "  )\n",
        "  return response\n",
        "\n",
        "print(\"Chat function defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZG_N4ezZaOm",
        "outputId": "36574b6f-46f3-4aba-f939-7abb50530a77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "MXuKSIeeaNKF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "welcome_message = \"**Assalam-o-Alaikum!** üëã I'm coding friend of laiba, your coding companion. You can talk to me in English, Urdu, or Roman Urdu - I'll respond in the same language you use. How are you feeling today?\"\n",
        "chat_history.append((\"\",welcome_message))\n",
        "\n",
        "buffer_memory.save_context(\n",
        "    {\"input\": \"Hello\"},\n",
        "    {\"output\": welcome_message}\n",
        ")\n",
        "window_memory.save_context(\n",
        "    {\"input\": \"Hello\"},\n",
        "    {\"output\": welcome_message}\n",
        ")\n",
        "def respond(message, history):\n",
        "  if not message:\n",
        "    return \"\",history\n",
        "\n",
        "  if message.lower() in [\"exit\",\"quit\",\"bye\",\"Khuda Hafiz\", \"Allah Hafiz\"]:\n",
        "    farewell = \"**Allah Hafiz!** Take Care of yourself. __Reminder, Seeking Help is a sign of strength_ üíô\"\n",
        "    return \"\",history\n",
        "\n",
        "  response = chat_with_bot(message)\n",
        "\n",
        "  history.append((message, response))\n",
        "  return \"\",history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"# Coding Chatbot - Laiba ka Coding Friend\")\n",
        "\n",
        "  chatbot = gr.Chatbot(\n",
        "      chat_history,\n",
        "      height=400\n",
        "  )\n",
        "  msg = gr.Textbox(\n",
        "      show_label=False,\n",
        "      placeholder=\"Type your message here...\"\n",
        "  )\n",
        "  with gr.Row():\n",
        "      submit = gr.Button(\"Send\")\n",
        "      clear = gr.Button(\"Clear\")\n",
        "\n",
        "  gr.Markdown(\"This chatbot provides coding support in C, C++, Python, Java, Javascript, HTML, CSS\")\n",
        "\n",
        "  msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "  submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
        "  clear.click(lambda: (chat_history[:1], \"\"), None, [chatbot, msg])\n",
        "\n",
        "  demo.launch(share=True)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "lqeXe1e0aUpA",
        "outputId": "14aee7b5-8df0-4b27-f321-af9a2a31ec3c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-5c7b902f196e>:32: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e9bf383ae09867d209.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e9bf383ae09867d209.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}